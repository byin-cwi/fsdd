{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../utils')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from fsdd import TorchFSDD, collate_fn\n",
    "from display import show_results\n",
    "from helpers import TrimMFCCs, Standardize\n",
    "import math, itertools, librosa, numpy as np, sigment as sig, sklearn.preprocessing, sklearn.metrics\n",
    "import matplotlib.pyplot as plt, librosa.display; plt.style.use('ggplot');\n",
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch, torchaudio, torchvision\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Set CUDA device (if available)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set seed, sample rate and labels\n",
    "torch.manual_seed(0)\n",
    "sr = 8000\n",
    "fsdd_labels = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of MFCCs to 39\n",
    "n_mfcc = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing transformations\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchaudio.transforms.MFCC(sample_rate=sr, n_mfcc=n_mfcc+1),\n",
    "    TrimMFCCs(),\n",
    "    Standardize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size, shuffling and number of workers\n",
    "loader_params = {'batch_size': 64, 'shuffle': True, 'num_workers': 0}\n",
    "\n",
    "# Create training, validation and test set batch iterators\n",
    "training_set = TorchFSDD('train', transform=transform)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, collate_fn=collate_fn, **loader_params)\n",
    "validation_set = TorchFSDD('validation', transform=transform)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, collate_fn=collate_fn, **loader_params)\n",
    "test_set = TorchFSDD('test', transform=transform)\n",
    "test_generator = torch.utils.data.DataLoader(test_set, collate_fn=collate_fn, batch_size=len(test_set), num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve MFCCs for a sample training digit\n",
    "mfccs, label = next(iter(training_set))\n",
    "X = mfccs.squeeze().numpy()\n",
    "\n",
    "# Plot the MFCCs for the digit\n",
    "plt.figure(figsize=(8, 5))\n",
    "librosa.display.specshow(X, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title(f'Mel-Frequency Cepstral Coefficients for sample audio of digit {label}')\n",
    "plt.ylabel('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, fc_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleDict({\n",
    "            # Bidirectional single-layer LSTM\n",
    "            'lstm': nn.LSTM(n_mfcc, hidden_size, num_layers=1, batch_first=True, bidirectional=True),\n",
    "            # Fully-connected classification layer\n",
    "            'fc1': nn.Linear(hidden_size*2, fc_size),\n",
    "            # (Pre-)Softmax layer for digit probabilities\n",
    "            'fc2': nn.Linear(fc_size, len(fsdd_labels)),\n",
    "        })\n",
    " \n",
    "    def forward(self, x, x_lengths):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor (B x T_max x D)\n",
    "            Batch tensor of padded MFCC sequences.\n",
    "        \n",
    "        x_lengths: Tensor (B)\n",
    "            Tensor of lengths for each sequence in the batch.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieve batch size\n",
    "        batch_size = len(x)\n",
    "\n",
    "        # Pack the padded Tensor into a PaddedSequence\n",
    "        x_packed = pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "        \n",
    "        # Pass the PackedSequence through the bidirectional LSTM cell (x = final hidden state vectors)\n",
    "        x_packed, (x, cell) = self.model['lstm'](x_packed)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # Shape (x): n_layers*2 x B x h_dim\n",
    "        \n",
    "        # Reshape the final hidden state vectors\n",
    "        x = x.transpose(1, 2).reshape(-1, batch_size).transpose(1, 0)\n",
    "        # Shape: B x h_dim*2\n",
    "        \n",
    "        # Pass final hidden state vectors through the fully-connected ReLU layer\n",
    "        x = F.relu(self.model['fc1'](x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # Shape: B x fc_dim\n",
    "        \n",
    "        # Pass to log-softmax layer for classification\n",
    "        return F.log_softmax(self.model['fc2'](x))\n",
    "        # Shape: B x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base hyper-parameters\n",
    "lr = 0.002\n",
    "epochs = 15\n",
    "\n",
    "best = (None, None, {}, -1)\n",
    "for i, (hidden_size, fc_size) in enumerate(itertools.product[(50, 100, 250, 500)]*2):\n",
    "    pbar = tqdm(total=epochs, position=i, leave=True, ncols='100%')\n",
    "    pbar.set_description(\"hidden_size={}, fc_size={} | epoch 1/{} | acc: train={:.2f}%, val={:.2f}%\".format(\n",
    "        hidden_size, fc_size, epochs, 0, 0))\n",
    "\n",
    "    # Configure model hyper-parameters and send model to GPU\n",
    "    model = LSTM(hidden_size=hidden_size, fc_size=fc_size).to(device)\n",
    "\n",
    "    # Set loss function and optimizer\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Keep track of training and validation accuracies\n",
    "    acc_history = {'train': np.zeros(epochs), 'val': np.zeros(epochs)}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        n_train, train_acc = 0, 0.\n",
    "        for batch, lengths, labels in training_generator:\n",
    "            # Transfer tensors to GPU\n",
    "            batch, lengths, labels = batch.to(device), lengths.to(device), labels.to(device)\n",
    "\n",
    "            # Reset the optimizer\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate predictions for batch\n",
    "            y = model(batch, lengths)\n",
    "            y_pred = torch.argmax(y, dim=1)\n",
    "\n",
    "            # Calculate and back-propagate loss\n",
    "            loss = criterion(y, labels)\n",
    "            loss.backward()\n",
    "            # Update the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            n_train += len(batch)\n",
    "            train_acc += (y_pred == labels).sum().item()\n",
    "        train_acc /= n_train\n",
    "\n",
    "        # Validation \n",
    "        model.eval()\n",
    "        n_val, val_acc = 0, 0.\n",
    "        with torch.no_grad():\n",
    "            for batch, lengths, labels in validation_generator:\n",
    "                # Transfer to GPU\n",
    "                batch, lengths, labels = batch.to(device), lengths.to(device), labels.to(device)\n",
    "\n",
    "                # Calculate predictions for batch\n",
    "                y = model(batch, lengths)\n",
    "                y_pred = torch.argmax(y, dim=1)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                n_val += len(batch)\n",
    "                val_acc += (y_pred == labels).sum().item()\n",
    "            val_acc /= n_val\n",
    "            \n",
    "        # Store accuracy history\n",
    "        acc_history['train'][epoch] = train_acc\n",
    "        acc_history['val'][epoch] = val_acc\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(\"hidden_size={}, fc_size={} | epoch {}/{} | acc: train={:.2f}%, val={:.2f}%\".format(\n",
    "            hidden_size, fc_size, epoch+1, epochs, train_acc * 100, val_acc * 100))\n",
    "        \n",
    "    if val_acc > best[-1]:\n",
    "        # Save the model and accuracy history\n",
    "        model_file = f'../models/lstm-{hidden_size}-{fc_size}.pt'\n",
    "        history_file = f'../models/lstm-{hidden_size}-{fc_size}-history.npz'\n",
    "        torch.save(model, model_file)\n",
    "        np.savez(history_file, train=acc_history['train'], val=acc_history['val'])\n",
    "        \n",
    "        # Update the best model\n",
    "        best = (model_file, history_file, {'hidden_size': hidden_size, 'fc_size': fc_size}, val_acc)\n",
    "        \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best model\n",
    "print(f'Best model: {best[2]}')\n",
    "\n",
    "# Load the best model and accuracy history\n",
    "model = torch.load(best[0]).to(device)\n",
    "acc_history = np.load(best[1])\n",
    "print('Training accuracy: {:.2f}%'.format(acc_history['train'][-1] * 100))\n",
    "print('Validation accuracy: {:.2f}%'.format(acc_history['val'][-1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy history\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.plot(acc_history['train'], c='r', label='training')\n",
    "plt.plot(acc_history['val'], c='b', label='validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify test recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Retrieve test set as a single batch\n",
    "batch, lengths, labels = next(iter(test_generator))\n",
    "batch, lengths, labels = batch.to(device), lengths.to(device), labels.to(device)\n",
    "\n",
    "# Calculate predictions for test set\n",
    "y = model(batch, lengths)\n",
    "y_pred = torch.argmax(y, dim=1)\n",
    "\n",
    "# Calculate confusion matrix and accuracy\n",
    "cm = sklearn.metrics.confusion_matrix(labels.numpy(), y_pred.detach().numpy(), labels=fsdd_labels)\n",
    "acc = np.diag(cm).sum() / cm.sum()\n",
    "show_results(acc, cm, dataset='test', labels=fsdd_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
